{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_kernel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader, SVD\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Obtaining dependency information for surprise from https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
      "Collecting scikit-surprise (from surprise)\n",
      "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "     ---------------------------------------- 0.0/772.0 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/772.0 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/772.0 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/772.0 kB 259.2 kB/s eta 0:00:03\n",
      "     - ----------------------------------- 30.7/772.0 kB 259.2 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 112.6/772.0 kB 467.6 kB/s eta 0:00:02\n",
      "     ----- ------------------------------ 112.6/772.0 kB 467.6 kB/s eta 0:00:02\n",
      "     ------ ----------------------------- 143.4/772.0 kB 472.1 kB/s eta 0:00:02\n",
      "     ------ ----------------------------- 143.4/772.0 kB 472.1 kB/s eta 0:00:02\n",
      "     ------ ----------------------------- 143.4/772.0 kB 472.1 kB/s eta 0:00:02\n",
      "     ---------- ------------------------- 225.3/772.0 kB 491.0 kB/s eta 0:00:02\n",
      "     ---------- ------------------------- 235.5/772.0 kB 464.5 kB/s eta 0:00:02\n",
      "     ------------ ----------------------- 276.5/772.0 kB 516.0 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 276.5/772.0 kB 516.0 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 276.5/772.0 kB 516.0 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 276.5/772.0 kB 516.0 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 276.5/772.0 kB 516.0 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 276.5/772.0 kB 516.0 kB/s eta 0:00:01\n",
      "     --------------- -------------------- 337.9/772.0 kB 395.3 kB/s eta 0:00:02\n",
      "     --------------- -------------------- 337.9/772.0 kB 395.3 kB/s eta 0:00:02\n",
      "     ------------------ ----------------- 389.1/772.0 kB 410.9 kB/s eta 0:00:01\n",
      "     ------------------ ----------------- 389.1/772.0 kB 410.9 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 450.6/772.0 kB 433.4 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 450.6/772.0 kB 433.4 kB/s eta 0:00:01\n",
      "     ---------------------- ------------- 481.3/772.0 kB 424.4 kB/s eta 0:00:01\n",
      "     ---------------------- ------------- 481.3/772.0 kB 424.4 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 501.8/772.0 kB 398.0 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 501.8/772.0 kB 398.0 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 563.2/772.0 kB 411.4 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 563.2/772.0 kB 411.4 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 634.9/772.0 kB 434.4 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 645.1/772.0 kB 414.4 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 645.1/772.0 kB 414.4 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 645.1/772.0 kB 414.4 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 645.1/772.0 kB 414.4 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 716.8/772.0 kB 403.7 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 747.5/772.0 kB 396.4 kB/s eta 0:00:01\n",
      "     -----------------------------------  768.0/772.0 kB 391.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ 772.0/772.0 kB 389.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.11.1)\n",
      "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp311-cp311-win_amd64.whl size=1077786 sha256=33de810c8ac52ab501d7db79a3cd8dc75e20c438701327fcee5a84989847f4d8\n",
      "  Stored in directory: c:\\users\\ishan\\appdata\\local\\pip\\cache\\wheels\\f4\\2b\\26\\e2a5eae55d3b7688995e66abe7f40473aac6c95ddd8ee174a8\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample dataset of dishes and ingredients\n",
    "data = {\n",
    "    'Dish': ['Spaghetti Bolognese', 'Chicken Curry', 'Caprese Salad', 'Beef Tacos'],\n",
    "    'Ingredients': ['spaghetti, beef, tomato sauce, onion', \n",
    "                    'chicken, curry paste, coconut milk, vegetables', \n",
    "                    'tomato, mozzarella cheese, basil, balsamic vinegar',\n",
    "                    'beef, tortillas, lettuce, tomato, cheese']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Content-Based Filtering\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['Ingredients'])\n",
    "\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Collaborative Filtering\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data_surprise = Dataset.load_from_df(df[['Dish', 'Ingredients']], reader)\n",
    "trainset, testset = train_test_split(data_surprise, test_size=0.2)\n",
    "\n",
    "# Fit SVD algorithm\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "def hybrid_recommendations(ingredients, num_recommendations=5):\n",
    "    # Content-Based Filtering\n",
    "    tfidf_matrix_input = tfidf.transform([ingredients])\n",
    "    cosine_sim_input = linear_kernel(tfidf_matrix_input, tfidf_matrix)\n",
    "    content_based_scores = list(enumerate(cosine_sim_input[0]))\n",
    "    content_based_scores = sorted(content_based_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Collaborative Filtering\n",
    "    user_id = trainset.to_inner_uid(0)\n",
    "    collaborative_based_scores = defaultdict(float)\n",
    "    for dish_id, _ in df.iterrows():\n",
    "        pred = algo.predict(user_id, dish_id)\n",
    "        collaborative_based_scores[dish_id] = pred.est\n",
    "        \n",
    "    # Combine recommendations\n",
    "    hybrid_scores = defaultdict(float)\n",
    "    for i in range(len(df)):\n",
    "        dish_id = content_based_scores[i][0]\n",
    "        hybrid_scores[dish_id] = 0.5 * content_based_scores[i][1] + 0.5 * collaborative_based_scores[dish_id]\n",
    "        \n",
    "    # Sort recommendations by hybrid score\n",
    "    hybrid_scores = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    recommended_dishes = [df.iloc[dish_id]['Dish'] for dish_id, _ in hybrid_scores[:num_recommendations]]\n",
    "    \n",
    "    return recommended_dishes\n",
    "\n",
    "# Example usage\n",
    "ingredients_input = 'beef, tomato sauce, onion'\n",
    "recommendations = hybrid_recommendations(ingredients_input)\n",
    "print(\"Recommended dishes based on input ingredients:\")\n",
    "for i, dish in enumerate(recommendations):\n",
    "    print(f\"{i+1}. {dish}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
